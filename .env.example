# Azure OpenAI Configuration for LLM-Enhanced Translation
# Copy this file to .env and fill in your values

# Azure OpenAI Endpoint (required)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Azure OpenAI API Key (required)
AZURE_OPENAI_API_KEY=your-api-key-here

# Azure OpenAI Deployment Name (optional, defaults to gpt-4.1)
AZURE_OPENAI_DEPLOYMENT=gpt-4.1

# Azure OpenAI API Version (optional, defaults to 2025-01-01-preview)
AZURE_OPENAI_API_VERSION=2025-01-01-preview

# Additional Optional Settings

# Cache LLM responses to reduce API calls (true/false)
LLM_CACHE_ENABLED=true

# Maximum tokens per request (default: 2000)
LLM_MAX_TOKENS=2000

# Temperature for code generation (0.0-1.0, default: 0.3)
LLM_TEMPERATURE=0.3

# Rate limiting delay between requests in milliseconds (default: 1000)
LLM_RATE_LIMIT_DELAY=1000

# Enable semantic enhancement of UIR (true/false)
LLM_SEMANTIC_ENHANCEMENT=true

# Translation method: 'direct' or 'ast-guided' (default: ast-guided)
LLM_TRANSLATION_METHOD=ast-guided